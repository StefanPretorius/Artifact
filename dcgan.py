# -*- coding: utf-8 -*-
"""DCGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15qn9TsdetXP5qWpOiwp0HGBnl-vJBJBf

# DCGAN - Deep Convolutional GANs

# Importing the libraries
"""

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import time
from tensorflow.keras import layers
from tensorflow.keras.preprocessing import image_dataset_from_directory
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2DTranspose
tf.__version__

"""# Loading and preprocessing the dataset"""

# Path to the dataset directory
dataset_directory = r'C:\Users\NWU-4060-2\Desktop\ITRI 671 - Artifact\Dataset\TypeII'

# Define the batch size
batch_size = 30

# Load the dataset
X_train = image_dataset_from_directory(
    dataset_directory,
    labels=None,
    image_size=(128, 128),
    color_mode='grayscale',
    batch_size=batch_size,
    shuffle=True
)


# Function to normalize and reshape images
def normalize_and_reshape(images):
    images = tf.cast(images, tf.float32)
    images = (images - 127.5) / 127.5
    images = tf.reshape(images, (-1, 128, 128, 1))
    return images


# Apply the normalization and reshaping function
train_ds = X_train.map(normalize_and_reshape)

# Check the shape of the dataset
for images in train_ds.take(1):
    print(images.shape)

train_ds.element_spec

i = np.random.randint(0, 30)
print(i)
# Convert the dataset to a NumPy array
train_ds_numpy = list(train_ds.as_numpy_iterator())

# Access the image using the index
plt.imshow(train_ds_numpy[i][0], cmap='gray');

buffer_size = 870
batch_size = 30
print(type(train_ds))
print(train_ds.element_spec)

"""# Building the generator"""

def build_generator():
    network = tf.keras.Sequential()

    # Dense layer: 8x8x256 units
    network.add(layers.Dense(units=8*8*256, use_bias=False, input_shape=(100,)))
    network.add(layers.BatchNormalization())
    network.add(layers.LeakyReLU())

    # Reshape to 8x8x256
    network.add(layers.Reshape((8, 8, 256)))

    # Transpose Conv Layer 1: 8x8x256 -> 16x16x128
    network.add(layers.Conv2DTranspose(filters=128, kernel_size=(5, 5), padding='same', strides=(2, 2), use_bias=False))
    network.add(layers.BatchNormalization())
    network.add(layers.LeakyReLU())

    # Transpose Conv Layer 2: 16x16x128 -> 32x32x64
    network.add(layers.Conv2DTranspose(filters=64, kernel_size=(5, 5), padding='same', strides=(2, 2), use_bias=False))
    network.add(layers.BatchNormalization())
    network.add(layers.LeakyReLU())

    # Transpose Conv Layer 3: 32x32x64 -> 64x64x32
    network.add(layers.Conv2DTranspose(filters=32, kernel_size=(5, 5), padding='same', strides=(2, 2), use_bias=False))
    network.add(layers.BatchNormalization())
    network.add(layers.LeakyReLU())

    # Transpose Conv Layer 4: 64x64x32 -> 128x128x1 (Final output)
    network.add(layers.Conv2DTranspose(filters=1, kernel_size=(5, 5), padding='same', strides=(2, 2), use_bias=True, activation='tanh'))

    network.summary()

    return network

generator = build_generator()

noise = tf.random.normal([1, 100])
noise

generated_image = generator(noise, training = False)

generated_image.shape

plt.imshow(generated_image[0, :,:,0], cmap='gray');

"""# Building the discriminator"""

def build_discriminator():
    network = tf.keras.Sequential()

    # 64 filters, 14x14x64
    network.add(layers.Conv2D(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same', input_shape=[128, 128, 1]))
    network.add(layers.LeakyReLU())
    network.add(layers.Dropout(0.3))

    # 128 filters, 7x7x128
    network.add(layers.Conv2D(filters=128, kernel_size=(5, 5), strides=(2, 2), padding='same'))
    network.add(layers.BatchNormalization())
    network.add(layers.LeakyReLU())
    network.add(layers.Dropout(0.3))

    # 256 filters, 4x4x256
    network.add(layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(2, 2), padding='same'))
    network.add(layers.BatchNormalization())
    network.add(layers.LeakyReLU())
    network.add(layers.Dropout(0.3))

    # 512 filters, 2x2x512
    network.add(layers.Conv2D(filters=512, kernel_size=(5, 5), strides=(2, 2), padding='same'))
    network.add(layers.BatchNormalization())
    network.add(layers.LeakyReLU())
    network.add(layers.Dropout(0.3))

    network.add(layers.Flatten())
    network.add(layers.Dense(1))

    network.summary()

    return network

discriminator = build_discriminator()

discriminator(generated_image, training = False) # logits

"""# Error calculation"""

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)

tf.ones_like(1)

def discriminator_loss(expected_output, fake_output):
  real_loss = cross_entropy(tf.ones_like(expected_output), expected_output)
  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
  total_loss = real_loss + fake_loss
  return total_loss

def generator_loss(fake_output):
  return cross_entropy(tf.ones_like(fake_output), fake_output)

generator_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002)
discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002)

"""# Training the GAN and visualizing the results"""

train_ds

epochs = 1000
noise_dimension = 100
number_of_images = 16

batch_size, noise_dimension

@tf.function
def train(images):
  noise = tf.random.normal([batch_size, noise_dimension])

  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
    generated_images = generator(noise, training = True)

    expected_output = discriminator(images, training = True)
    fake_output = discriminator(generated_images, training = True)

    gen_loss = generator_loss(fake_output)
    disc_loss = discriminator_loss(expected_output, fake_output)

  generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)
  discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

  generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))
  discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))

tf.config.run_functions_eagerly(True)
X_train_batch = X_train.as_numpy_iterator().next()
train(X_train_batch)

test_images = tf.random.normal([number_of_images, noise_dimension])
test_images.shape

def train_gan(dataset, epochs, test_images):
  for epoch in range(epochs):
    initial = time.time()
    for image_batch in dataset:
      train(image_batch)

    print('Epoch: ', epoch + 1)
    generated_images = generator(test_images, training = False)
    fig = plt.figure(figsize = (4,4))
    for i in range(generated_images.shape[0]):
      plt.subplot(4,4,i + 1)
      plt.imshow(generated_images[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
      plt.axis('off')
    plt.savefig('img_epoch_{:04d}'.format(epoch+1))
    plt.show()
    print('Time taken to process epoch {} was {} seconds'.format(epoch + 1, time.time() - initial))

train_gan(train_ds, epochs, test_images)

import os
from PIL import Image

# Directory for saving generated images after each epoch
os.makedirs('generated_images', exist_ok=True)
os.makedirs('saved_images', exist_ok=True)

# Save images after each epoch
def save_generated_images(epoch, generator, latent_dim, num_examples=16):
    noise = tf.random.normal([num_examples, latent_dim])
    generated_images = generator(noise, training=False)
    generated_images = (generated_images * 127.5 + 127.5).numpy().astype('uint8')  # Rescale to [0, 255]

    for i, img in enumerate(generated_images):
        img = Image.fromarray(img[:, :, 0], 'L')  # Assuming grayscale
        img.save(f"generated_images/epoch_{epoch}_image_{i}.png")

# Saving the model after training
def save_model(generator, discriminator):
    generator.save('generator_model.h5')
    discriminator.save('discriminator_model.h5')

save_model(generator, discriminator)

# Load saved model and generate images
def generate_images_from_model(model_path, num_images, latent_dim):
    generator = tf.keras.models.load_model(model_path)
    noise = tf.random.normal([num_images, latent_dim])
    generated_images = generator(noise, training=False)
    generated_images = (generated_images * 127.5 + 127.5).numpy().astype('uint8')

    os.makedirs('saved_images', exist_ok=True)
    for i, img in enumerate(generated_images):
        img = Image.fromarray(img[:, :, 0], 'L')  # Assuming grayscale images
        img.save(f'Generated_Images/generated_image_{i+1}.png')


generate_images_from_model('generator_model.h5', num_images=10, latent_dim=100)